% Encoding: UTF-8

@inproceedings{misra2021end,
  title={An end-to-end transformer model for 3d object detection},
  author={Misra, Ishan and Girdhar, Rohit and Joulin, Armand},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2906--2917},
  year={2021}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{jain2019attention,
  title={Attention is not explanation},
  author={Jain, Sarthak and Wallace, Byron C},
  journal={arXiv preprint arXiv:1902.10186},
  year={2019}
}

@article{Att.2017,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part I 16},
  pages={213--229},
  year={2020},
  organization={Springer}
}

@inproceedings{wang2022detr3d,
  title={Detr3d: 3d object detection from multi-view images via 3d-to-2d queries},
  author={Wang, Yue and Guizilini, Vitor Campagnolo and Zhang, Tianyuan and Wang, Yilun and Zhao, Hang and Solomon, Justin},
  booktitle={Conference on Robot Learning},
  pages={180--191},
  year={2022},
  organization={PMLR}
}

@inproceedings{abeloos2022explaining,
  title={Explaining object detectors: the case of transformer architectures},
  author={Abeloos, Baptiste and Herbin, St{\'e}phane},
  booktitle={Workshop on Trustworthy Artificial Intelligence as a part of the ECML/PKDD 22 program},
  year={2022}
}

@article{yu2022ex,
  title={eX-ViT: A Novel eXplainable Vision Transformer for Weakly Supervised Semantic Segmentation},
  author={Yu, Lu and Xiang, Wei and Fang, Juan and Chen, Yi-Ping Phoebe and Chi, Lianhua},
  journal={arXiv preprint arXiv:2207.05358},
  year={2022}
}

@inproceedings{chefer2021generic,
  title={Generic attention-model explainability for interpreting bi-modal and encoder-decoder transformers},
  author={Chefer, Hila and Gur, Shir and Wolf, Lior},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={397--406},
  year={2021}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@article{bach2015pixel,
  title={On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation},
  author={Bach, Sebastian and Binder, Alexander and Montavon, Gr{\'e}goire and Klauschen, Frederick and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  journal={PloS one},
  volume={10},
  number={7},
  pages={e0130140},
  year={2015},
  publisher={Public Library of Science San Francisco, CA USA}
}

@article{wang2021multi,
  title={Multi-modal 3d object detection in autonomous driving: a survey},
  author={Wang, Yingjie and Mao, Qiuyu and Zhu, Hanqi and Deng, Jiajun and Zhang, Yu and Ji, Jianmin and Li, Houqiang and Zhang, Yanyong},
  journal={arXiv preprint arXiv:2106.12735},
  year={2021}
}

@article{huang2022multi,
  title={Multi-modal sensor fusion for auto driving perception: A survey},
  author={Huang, Keli and Shi, Botian and Li, Xiang and Li, Xin and Huang, Siyuan and Li, Yikang},
  journal={arXiv preprint arXiv:2202.02703},
  year={2022}
}

@inproceedings{caesar2020nuscenes,
  title={nuscenes: A multimodal dataset for autonomous driving},
  author={Caesar, Holger and Bankiti, Varun and Lang, Alex H and Vora, Sourabh and Liong, Venice Erin and Xu, Qiang and Krishnan, Anush and Pan, Yu and Baldan, Giancarlo and Beijbom, Oscar},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11621--11631},
  year={2020}
}

@inproceedings{wang2020pillar,
  title={Pillar-based object detection for autonomous driving},
  author={Wang, Yue and Fathi, Alireza and Kundu, Abhijit and Ross, David A and Pantofaru, Caroline and Funkhouser, Tom and Solomon, Justin},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXII 16},
  pages={18--34},
  year={2020},
  organization={Springer}
}

@inproceedings{lang2019pointpillars,
  title={Pointpillars: Fast encoders for object detection from point clouds},
  author={Lang, Alex H and Vora, Sourabh and Caesar, Holger and Zhou, Lubing and Yang, Jiong and Beijbom, Oscar},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12697--12705},
  year={2019}
}

@article{chen2022polar,
  title={Polar parametrization for vision-based surround-view 3d detection},
  author={Chen, Shaoyu and Wang, Xinggang and Cheng, Tianheng and Zhang, Qian and Huang, Chang and Liu, Wenyu},
  journal={arXiv preprint arXiv:2206.10965},
  year={2022}
}

@article{abnar2020quantifying,
  title={Quantifying attention flow in transformers},
  author={Abnar, Samira and Zuidema, Willem},
  journal={arXiv preprint arXiv:2005.00928},
  year={2020}
}

@inproceedings{doll2022spatialdetr,
  title={SpatialDETR: Robust Scalable Transformer-Based 3D Object Detection From Multi-view Camera Images With Global Cross-Sensor Attention},
  author={Doll, Simon and Schulz, Richard and Schneider, Lukas and Benzin, Viviane and Enzweiler, Markus and Lensch, Hendrik PA},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXIX},
  pages={230--245},
  year={2022},
  organization={Springer}
}

@inproceedings{chefer2021transformer,
  title={Transformer interpretability beyond attention visualization},
  author={Chefer, Hila and Gur, Shir and Wolf, Lior},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={782--791},
  year={2021}
}

@article{lu2022transformers,
  title={Transformers in 3d point clouds: A survey},
  author={Lu, Dening and Xie, Qian and Wei, Mingqiang and Xu, Linlin and Li, Jonathan},
  journal={arXiv preprint arXiv:2205.07417},
  year={2022}
}

@inproceedings{ali2022xai,
  title={XAI for transformers: Better explanations through conservative propagation},
  author={Ali, Ameen and Schnake, Thomas and Eberle, Oliver and Montavon, Gr{\'e}goire and M{\"u}ller, Klaus-Robert and Wolf, Lior},
  booktitle={International Conference on Machine Learning},
  pages={435--451},
  year={2022},
  organization={PMLR}
}

@article{mondal2021xvitcos,
  title={xViTCOS: explainable vision transformer based COVID-19 screening using radiography},
  author={Mondal, Arnab Kumar and Bhattacharjee, Arnab and Singla, Parag and Prathosh, AP},
  journal={IEEE Journal of Translational Engineering in Health and Medicine},
  volume={10},
  pages={1--10},
  year={2021},
  publisher={IEEE}
}